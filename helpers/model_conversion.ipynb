{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this for getting the model I wanted from the training site, and making into a TF model.\n",
    "# I used lc0 and leela2onnx to convert it into a ONNX-model as an intermediary\n",
    "# Note: if you want to do inference, the #1 way to do that is probably to just download the weight file of your choice\n",
    "# and use the lc0-binary itself.\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"http://training.lczero.org/networks/?show_all=1\", \"networks.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"networks.html\") as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "network_iterations = [1, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2390]\n",
    "results = []\n",
    "for row in soup.find_all(\"tr\"):\n",
    "    for iter in network_iterations:\n",
    "        iteration_string = str(30000 + iter)\n",
    "        if iteration_string in row.contents[1]:\n",
    "            results.append((iteration_string, row.contents[5].contents[0]['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('networks/32390.pb', <http.client.HTTPMessage at 0x2cd03a94910>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# You could also download these manually if you want.\n",
    "os.makedirs(\"networks\", exist_ok=True)\n",
    "opener = urllib.request.build_opener()\n",
    "# Sneaky!\n",
    "opener.addheaders = [(\"User-agent\", \"Mozilla/5.0\")]\n",
    "urllib.request.install_opener(opener)\n",
    "iteration, href = results[0]\n",
    "urllib.request.urlretrieve(\"http://training.lczero.org\" + href, \"networks/\" + iteration + \".pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_image_data_format('channels_first')\n",
    "\n",
    "def block(last, i):\n",
    "    x = keras.layers.Conv2D(256, (3, 3), padding=\"same\", name=\"block{}/conv{}\".format(i, 1), activation=\"relu\")(last)\n",
    "    x = keras.layers.Conv2D(256, (3, 3), padding=\"same\", name=\"block{}/conv{}\".format(i, 2), activation=\"linear\")(x)\n",
    "    add = keras.layers.Add()([x, last])\n",
    "    rel = keras.layers.ReLU()(add)\n",
    "    return rel, add\n",
    "\n",
    "\n",
    "inputs = keras.Input((112, 8, 8))\n",
    "last = keras.layers.Conv2D(256, (3, 3), padding=\"same\", name=\"inputconv\")(inputs)\n",
    "last = keras.layers.ReLU()(last)\n",
    "inter_outputs = [last]\n",
    "for b in range(0, 20):\n",
    "    last, inter = block(last, b)\n",
    "    inter_outputs.append(inter)\n",
    "\n",
    "policy_conv = keras.layers.Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\", name=\"policy_conv\")(last)\n",
    "flatten = keras.layers.Flatten(data_format=\"channels_last\")(policy_conv)\n",
    "policy_output = keras.layers.Dense(1858, activation=\"linear\", name=\"policy_dense\")(flatten)\n",
    "\n",
    "value_conv = keras.layers.Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\", name=\"value_conv\")(last)\n",
    "flatten = keras.layers.Flatten(data_format=\"channels_last\")(value_conv)\n",
    "value_dense = keras.layers.Dense(128, activation=\"relu\", name=\"value_dense_1\")(flatten)\n",
    "value_output = keras.layers.Dense(1, activation=\"tanh\", name=\"value_output\")(value_dense)\n",
    "\n",
    "model = keras.Model(inputs, [policy_output, value_output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "from onnx import numpy_helper\n",
    "_model = onnx.load(\"network.onnx\")\n",
    "INTIALIZERS = _model.graph.initializer\n",
    "weights = {}\n",
    "for initializer in INTIALIZERS:\n",
    "    W = numpy_helper.to_array(initializer)\n",
    "    if len(W.shape) > 2:\n",
    "        weights[initializer.name[1:]] = np.moveaxis(W, [0, 1], [-1, -2])\n",
    "    else:\n",
    "        weights[initializer.name[1:]] = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.name == \"value_dense_1\":\n",
    "        layer.set_weights([weights[\"value/dense1/matmul/w\"], weights[\"value/dense1/add/w\"]])\n",
    "    elif layer.name == \"value_output\":\n",
    "        layer.set_weights([weights[\"value/dense2/matmul/w\"], weights[\"value/dense2/add/w\"]])\n",
    "    elif \"value_conv\" in layer.name:\n",
    "        layer.set_weights([weights[\"value/conv/w/kernel\"], weights[\"value/conv/w/bias\"]])\n",
    "    elif \"policy_conv\" in layer.name:\n",
    "        layer.set_weights([weights[\"policy/conv/w/kernel\"], weights[\"policy/conv/w/bias\"]])\n",
    "    elif \"policy_dense\" in layer.name:\n",
    "        layer.set_weights([weights[\"policy/dense/matmul/w\"], weights[\"output/policy/w\"]])\n",
    "    elif \"conv\" in layer.name:\n",
    "        layer.set_weights([weights[layer.name + \"/w/kernel\"], weights[layer.name + \"/w/bias\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 43). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/tf_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/tf_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/tf_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
