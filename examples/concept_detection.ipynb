{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept detection\n",
    "This notebook shows how to create a simple concept detection (https://arxiv.org/abs/1610.01644, https://arxiv.org/abs/1711.11279) pipeline using all the tools found in this repo.\n",
    "\n",
    "The main point of this is to show an use-case where it would be nice to be able to do something beyond just basic inference (which is done better through the lc0-binary itself, by converting your model to the ONNX-format anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's make our concept dataset. I included a big file of PGNs to make this a bit easier.\n",
    "# (This is from the elite-database, https://database.nikonoel.fr/)\n",
    "with open(\"database.pgn\") as f:\n",
    "    all_pgns = f.read().split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "\n",
    "# For our concept-function, we define it to be whether the player to move is in check.\n",
    "\n",
    "def concept_func(board: chess.Board):\n",
    "    return board.is_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import chess.pgn\n",
    "from leela_board import LeelaBoard\n",
    "\n",
    "positive_samples = []\n",
    "negative_samples = []\n",
    "number_of_samples = 5000\n",
    "# Now we can go through the PGNs one-by-one.\n",
    "for pgn in all_pgns:\n",
    "    # We read the pgn by using python-chess\n",
    "    game = chess.pgn.read_game(io.StringIO(pgn))\n",
    "    if game is not None:\n",
    "        # Here, the main star of the show appears.\n",
    "        data_board = LeelaBoard()\n",
    "        for move in game.mainline_moves():\n",
    "            # We push a move, updating the internal state...\n",
    "            data_board.push(move)\n",
    "            # And check if the player to move is in check (handy reference to the internal python-chess board)\n",
    "            if concept_func(data_board.pc_board):\n",
    "                # And get the current position in the correct input format!\n",
    "                positive_samples.append(data_board.lcz_features())\n",
    "            else:\n",
    "                negative_samples.append(data_board.lcz_features())\n",
    "    \n",
    "    # Make sure that we don't keep a lot of these around\n",
    "    positive_samples = positive_samples[:number_of_samples]\n",
    "    negative_samples = negative_samples[:number_of_samples]\n",
    "    # Stop when we have a balanced data set\n",
    "    if len(positive_samples) >= number_of_samples and len(negative_samples) >= number_of_samples:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "# Now, we can get our activations.\n",
    "# First, let's load the network.\n",
    "# (Make sure that you unzipped the archive provided by this repo first though.)\n",
    "network = keras.models.load_model(\"models/tf_model\")\n",
    "# Then, we make a submodel from the input to the tenth block of the model.\n",
    "# (You can look at the architecture just like a normal model, in this case by looking at model.summary())\n",
    "network.trainable = False\n",
    "# We attach a linear probe:\n",
    "inter_flat = keras.layers.Flatten()(network.get_layer(\"block10/conv1\").output)\n",
    "probe_output = keras.layers.Dense(1, activation=\"sigmoid\", kernel_regularizer=keras.regularizers.L1(0.01))(inter_flat)\n",
    "probe_model = keras.Model(network.inputs, probe_output)\n",
    "probe_model.compile(loss=keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(), run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Finally, the concept detection.\n",
    "# We make our training and testing dataset...\n",
    "labels = np.array([0] * len(negative_samples) + [1] * len(positive_samples))\n",
    "inputs = np.concatenate([negative_samples, positive_samples])\n",
    "\n",
    "shuffle_indices = np.arange(len(labels))\n",
    "np.random.shuffle(shuffle_indices)\n",
    "labels = labels[shuffle_indices]\n",
    "inputs = inputs[shuffle_indices]\n",
    "\n",
    "x_train, x_test, y_train, y_test = inputs[:4000], inputs[4000:], labels[:4000], labels[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
